#! /bin/bash

set -e

if [ $# != 1 ]; then
    echo "Usage: $0 <ZNS device (e.g., nvme0n2)>"
    exit 1
fi

DEV=$(echo $1 | sed 's/vme/g/g')
DEV_SECT_SIZE=$(cat /sys/block/$1/queue/hw_sector_size)
DEV_ZONE_SIZE_BLOCKS=$(cat /sys/block/$1/queue/chunk_sectors)
DEV_ZONE_SIZE=$(echo "${DEV_ZONE_SIZE_BLOCKS} * 512" | bc)
DEV_ZONES=$(cat /sys/block/$1/queue/nr_zones)

echo "#########################################################"
echo "####################### ZNS  SETUP ######################"
echo "#########################################################"
echo "---------------------------------------------------------"
printf 'DEV: %52s\n' "/dev/${DEV}"
echo "---------------------------------------------------------"
printf 'SECTOR_SIZE: %44s\n' "${DEV_SECT_SIZE}"
echo "---------------------------------------------------------"
printf 'ZONE_SIZE_BLOCKS: %39s\n' "${DEV_ZONE_SIZE_BLOCKS}"
echo "---------------------------------------------------------"
printf 'ZONE_SIZE_BYTES: %40s\n' "${DEV_ZONE_SIZE}"
echo "---------------------------------------------------------"
printf 'DEV_ZONES: %46s\n' "${DEV_ZONES}"
echo "---------------------------------------------------------"
echo ""

mkdir -p data

##################################
## fio options for specific ZNS ##
##################################
BS=$(echo "${DEV_SECT_SIZE} * ${DEV_ZONE_SIZE}" | bc)

# Use 300 finish zones as with ~1 finish/sec and at 50% rate limit we can do 1 finish every 2 seconds
# and benchmarks try to run for 10 minutes (10*60/2) = 300 and peak write bandwidth is 1.2GB/s = ~1 zone so within 10
# minutes we can fill (10*60) = 600 and we have a total of 904 zones
FINISH_SIZE=300
WRITE_ZONES=$(echo "${DEV_ZONES} - ${FINISH_SIZE}" | bc) # All but the fill zones

# our setup only has 20 cores and we have a polling thread for each job
# therefore we max to 9 write jobs, as there is 1 concurrent trim job
# issuing zone finish with also its own polling thread
WRITE_IODEPTH=(1 2 3 4 5 6 7) 

echo "#########################################################"
echo "###################### BENCH  SETUP #####################"
echo "#########################################################"
echo "---------------------------------------------------------"
printf 'FINISH_ZONES (Empty zones for finish): %18s\n' "${FINISH_SIZE}"
echo "---------------------------------------------------------"
printf 'WRITE_ZONES (Empty zones for writes): %19s\n' "${WRITE_ZONES}"
echo "---------------------------------------------------------"
printf 'WRITE_NUMJOBS: %42s\n' "${WRITE_IODEPTH[*]}"
echo "---------------------------------------------------------"
echo ""

echo "Benchmarking ZNS Device Finish Limit"
sudo nvme zns reset-zone /dev/$1 -a
sudo env "DEV=${DEV}" "FINISH_SIZE=${FINISH_SIZE}" ../fio/fio --output-format=json --output=data/bw.json job-finish.fio

BW=$(cat data/bw.json | grep -i "bw_bytes" | awk 'FNR == 2 {print $3}' | sed 's/,//g')
echo "Found Sustainable BW for Finish: ${BW} B/sec"

for write_iodepth in ${WRITE_IODEPTH[@]}; do
    WRITE_SIZE=$(echo "scale=0; ${WRITE_ZONES} / ${write_iodepth}" | bc)

    echo ""
    echo "Benchmarking with CONCURRENT WRITE JOBS: ${write_iodepth}"
    sudo nvme zns reset-zone /dev/$1 -a

    CONCUR_WRITE_SIZE=$(echo "scale=0; ${WRITE_ZONES} / ${write_iodepth}" | bc)

    # Write job has a ramp time because fio will directly issue 2 finishs and then realize it needs to rate limit, therefore we don't want to account this period in the write performance
    sudo env "DEV=${DEV}" "CONCUR_WRITE_SIZE=${CONCUR_WRITE_SIZE}" "WRITE_IODEPTH=${write_iodepth}" "FINISH_SIZE=${FINISH_SIZE}" ../fio/fio --output-format=json --output=data/data-write_iod_${write_iodepth}.json job.fio
done

