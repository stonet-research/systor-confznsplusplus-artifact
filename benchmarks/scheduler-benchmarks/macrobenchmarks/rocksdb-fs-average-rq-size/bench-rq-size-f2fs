#! /bin/bash

set -e

SCRIPT_DIR=$(cd $(dirname "${BASH_SOURCE[0]}") && pwd)
cd ${SCRIPT_DIR}
source ../common.sh

# Check input
if [ $# != 1 ]; then
    echo "Usage: $0 <ZNS device (e.g., nvme0n2)>"
    exit 1
fi
DEV=$1

# Output
DATA_FILE=${DEV}-req-f2fs-$(date +"%Y_%m_%d_%I_%M_%p").dat
DATA_FILE_OUT=${DEV}-out-req-f2fs-$(date +"%Y_%m_%d_%I_%M_%p").dat

# ZNS vars
get_device_info ${DEV}
# RocksDB vars
get_default_rocksdb_vars ${DEV}

echo mq-deadline | sudo tee /sys/block/${DEV}/queue/scheduler
sudo nvme zns reset-zone /dev/${DEV} -a
## Start the F2FS benchmark
# TODO: REMOVE STATIC LINK AND HAVE MODULE FOR ROCKSDB AND ZENFS
DEVNULL=$(sudo ${NULLBLK} 4096 7168)  # TODO: remove hardcode
export DEVNULL
sudo env "PATH=${PATH}" mkfs.f2fs -f -m -c /dev/${DEV} /dev/${DEVNULL}
sudo mkdir -p /mnt/bench-f2fs
sudo mount -t f2fs /dev/${DEVNULL} /mnt/bench-f2fs

# (sudo ~/src/bpftrace/build/src/bpftrace ./trace.bt $1 -o data/${DATA_FILE}) &
sudo bpftrace ${SCRIPT_DIR}/blk_write_io_size_final.bt ${DEV} -o ${SCRIPT_DIR}data/${DATA_FILE}-fill &
bpfpid=$!
# Sleep to ensure bpftrace has started
sleep 10

# Fill the 1st namespace with data
sudo ${DBBENCH} \
    --db=/mnt/bench-f2fs/db0 --wal_dir=/mnt/bench-f2fs/wal0 \
    --benchmarks=fillrandom \
    --use_existing_db=0 \
    --num=10000000 \
    --compression_type=none \
    --value_size=4000 \
    --key_size=16 \
    --target_file_size_base=$(($ZONE_CAP * 2 * 65 / 100)) \
    --use_direct_io_for_flush_and_compaction \
    --max_bytes_for_level_multiplier=4 \
    --max_background_jobs=8 \
    --use_direct_reads \
    --write_buffer_size=${WB_SIZE} \
    --seed=42 \
    --histogram=1 > ${SCRIPT_DIR}/data/${DATA_FILE_OUT} \
    --use_fsync=1 \
    --sync=1
sudo kill $bpfpid

workload_switch_time=$(date +"%H:%M:%S")
sudo bpftrace ${SCRIPT_DIR}/blk_write_io_size_final.bt ${DEV} -o ${SCRIPT_DIR}/data/${DATA_FILE}-overwrite &
bpfpid=$!
sleep 10

# Start overwriting and generating some active GC
sudo ${DBBENCH} \
    --db=/mnt/bench-f2fs/db0 --wal_dir=/mnt/bench-f2fs/wal0 \
    --benchmarks=overwrite \
    --use_existing_db=1 \
    --num=$((10000000/8)) \
    --compression_type=none \
    --value_size=4000 \
    --key_size=16 \
    --target_file_size_base=$(($ZONE_CAP * 2 * 65 / 100)) \
    --use_direct_io_for_flush_and_compaction \
    --max_bytes_for_level_multiplier=4 \
    --max_background_jobs=8 \
    --use_direct_reads \
    --write_buffer_size=${WB_SIZE} \
    --seed=42 \
    --histogram=1 >> ${SCRIPT_DIR}/data/${DATA_FILE_OUT} \
    --use_fsync=1 \
    --sync=1
sudo kill $bpfpid

wait $!\
echo "(${workload_switch_time}, 4)" >> ${SCRIPT_DIR}/data/${DATA_FILE}
